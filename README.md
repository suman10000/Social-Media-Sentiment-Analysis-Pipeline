ğŸ“Š Social Media Sentiment Analysis Pipeline

A full-scale modern data engineering pipeline that ingests large-scale social media data, performs sentiment analysis using NLP, processes data with Apache Spark, stores it in Snowflake using a Star Schema warehouse design, applies enterprise-level security controls, and enables advanced analytical insights.

ğŸ“Œ Table of Contents

ğŸš€ Project Overview

ğŸ— System Architecture

ğŸ§  Key Features

ğŸ“Š Tech Stack

ğŸ“ Project Structure

âš™ Data Pipeline Flow

ğŸ“ˆ Analytics Capabilities

ğŸ” Security & Governance

âš¡ Big Data & Streaming

â–¶ How to Run Locally

ğŸ“š What This Project Demonstrates

ğŸ‘¨â€ğŸ’» Author

ğŸš€ Project Overview

This project implements a real-world scalable sentiment analytics platform designed to:

â€¢ Process large-scale Twitter data (1.6M+ records)
â€¢ Perform NLP-based sentiment classification
â€¢ Build a structured Data Warehouse (Star Schema)
â€¢ Execute advanced SQL analytics
â€¢ Optimize performance using Snowflake features
â€¢ Apply enterprise security principles
â€¢ Demonstrate Spark batch & streaming processing

The architecture mirrors production-grade data engineering systems used in modern analytics-driven organizations.

ğŸ— System Architecture
Raw Social Media Dataset (CSV)
            â†“
Python ETL (Cleaning + NLP Sentiment Analysis)
            â†“
Dimension & Fact Table Construction
            â†“
Snowflake Data Warehouse (Star Schema)
            â†“
Apache Spark Batch Processing
            â†“
Structured Streaming Simulation
            â†“
Advanced SQL Analytics
            â†“
Clustering + Time Travel Optimization
            â†“
Role-Based Access & Secure Views
            â†“
Interactive Analytics & Reporting
ğŸ§  Key Features

âœ” Star Schema Data Warehouse Design
âœ” Python-based ETL Pipeline
âœ” NLP Sentiment Analysis (VADER)
âœ” Apache Spark Batch Processing
âœ” Structured Streaming Simulation
âœ” Advanced SQL (CTE, Window Functions, Ranking)
âœ” Snowflake Clustering & Time Travel
âœ” Role-Based Access Control (RBAC)
âœ” Secure View-based Data Masking
âœ” Performance Optimization Strategies

ğŸ“Š Tech Stack
Layer	Technology
ETL	Python, Pandas, VADER
Big Data	Apache Spark (PySpark)
Warehouse	Snowflake
Analytics	Advanced SQL
Optimization	Clustering, Time Travel
Security	RBAC + Secure Views
Streaming	Structured Streaming Simulation
Version Control	Git & GitHub
ğŸ“ Project Structure
Social-Media-Sentiment-Analysis-Pipeline/
â”‚
â”œâ”€â”€ etl.py
â”œâ”€â”€ warehouse_prep.py
â”œâ”€â”€ spark_batch.py
â”œâ”€â”€ spark_streaming.py
â”‚
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ 01_schema_setup.sql
â”‚   â”œâ”€â”€ 02_advanced_queries.sql
â”‚   â”œâ”€â”€ 03_optimization.sql
â”‚   â””â”€â”€ 04_security.sql
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

âš™ Data Pipeline Flow
ğŸ”„ Batch ETL
Extract â†’ Clean â†’ Transform â†’ Sentiment Scoring â†’ Load

â€¢ Removes noise (URLs, mentions, symbols)
â€¢ Applies VADER sentiment scoring
â€¢ Generates structured dataset
â€¢ Builds surrogate keys for dimensions
â€¢ Constructs fact table

ğŸ—„ Data Warehouse Layer

Star Schema Implementation:

Fact Table

fact_sentiment

Dimension Tables

dim_user

dim_date

dim_platform

dim_location

Designed for efficient OLAP-style analytical querying.

ğŸ“ˆ Analytics Capabilities

Examples of insights generated:

ğŸ“Š Sentiment distribution by date

ğŸ“… Rolling 7-day sentiment average

ğŸ† Most negative days ranking

ğŸ“ˆ Trend analysis using window functions

ğŸ” Sentiment segmentation by platform/location

âš¡ Hybrid Spark + Snowflake analytics

ğŸ” Security & Governance

Implemented using enterprise design principles:

Role-Based Access Control (RBAC)

Secure View-based column masking

Schema-level privilege management

Separation of administrative roles

Least privilege enforcement model

âš¡ Big Data & Streaming
ğŸš€ Apache Spark Batch Processing

â€¢ Aggregates sentiment counts
â€¢ Computes daily averages
â€¢ Handles 1.6M+ records efficiently

ğŸ”„ Structured Streaming (Simulation)

â€¢ Real-time sentiment aggregation simulation
â€¢ Micro-batch processing model
â€¢ Continuous sentiment monitoring concept

â–¶ How to Run Locally
1ï¸âƒ£ Install dependencies
pip install -r requirements.txt
2ï¸âƒ£ Run ETL Pipeline
python etl.py
3ï¸âƒ£ Generate Warehouse Tables
python warehouse_prep.py
4ï¸âƒ£ Run Spark Batch Job
py -3.10 spark_batch.py
5ï¸âƒ£ Run Streaming Simulation
py -3.10 spark_streaming.py
ğŸ“š What This Project Demonstrates

This project showcases:

âœ… End-to-end Data Engineering pipeline
âœ… Cloud Data Warehouse implementation
âœ… Big Data processing with Spark
âœ… Advanced SQL analytics mastery
âœ… Enterprise security design
âœ… Performance tuning techniques
âœ… Production-style project organization

ğŸ‘¨â€ğŸ’» Author

Suman Dandapat
Data Engineering & Analytics Enthusiast