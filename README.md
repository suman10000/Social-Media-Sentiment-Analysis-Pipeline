# ğŸ“Š Social Media Sentiment Analysis Pipeline

> A full-scale modern data engineering pipeline that ingests large-scale social media data, performs NLP-based sentiment analysis, processes data using Apache Spark, stores it in Snowflake using a Star Schema warehouse design, applies enterprise-level security controls, enables performance optimization, supports semi-structured data handling, and provides interactive analytical insights through a Streamlit dashboard.

---

## ğŸ“Œ Table of Contents

- [ğŸš€ Project Overview](#-project-overview)
- [ğŸ— System Architecture](#-system-architecture)
- [ğŸ§  Key Features](#-key-features)
- [ğŸ“Š Tech Stack](#-tech-stack)
- [ğŸ“ Project Structure](#-project-structure)
- [âš™ Data Pipeline Flow](#-data-pipeline-flow)
- [ğŸ“ˆ Analytics Capabilities](#-analytics-capabilities)
- [ğŸ” Security & Governance](#-security--governance)
- [âš¡ Big Data & Streaming](#-big-data--streaming)
- [ğŸ“Š Interactive Dashboard](#-interactive-dashboard)
- [â–¶ How to Run Locally](#-how-to-run-locally)
- [ğŸ“š What This Project Demonstrates](#-what-this-project-demonstrates)
- [ğŸ‘¨â€ğŸ’» Author](#-author)

---

## ğŸš€ Project Overview

This project implements a real-world scalable sentiment analytics platform designed to:

- Process large-scale Twitter data (1.6M+ records)
- Perform NLP-based sentiment classification
- Build a structured Data Warehouse (Star Schema)
- Execute advanced SQL analytics
- Optimize performance using Snowflake features
- Handle semi-structured JSON data
- Apply enterprise security principles
- Demonstrate Spark batch processing
- Provide an interactive visualization dashboard

The architecture mirrors production-grade data engineering systems used in modern analytics-driven organizations.

---

## ğŸ— System Architecture

![Architecture Diagram](architecture_diagram.png)

```
Raw Social Media Dataset (CSV)
            â†“
Modular Python ETL (Extract â†’ Transform â†’ Load)
            â†“
Sentiment Analysis (VADER NLP)
            â†“
Dimension & Fact Table Construction
            â†“
Snowflake Data Warehouse (Star Schema)
            â†“
Advanced SQL Analytics
            â†“
Clustering + Time Travel Optimization
            â†“
Semi-Structured JSON Handling (VARIANT)
            â†“
Role-Based Access & Secure Views
            â†“
Apache Spark Batch Processing
            â†“
Interactive Streamlit Dashboard
```

---

## ğŸ§  Key Features

âœ” Modular ETL Architecture (Extract / Transform / Load)  
âœ” NLP Sentiment Analysis (VADER)  
âœ” Star Schema Data Warehouse Design  
âœ” Advanced SQL (CTE, Window Functions, Ranking)  
âœ” Snowflake Clustering & Time Travel  
âœ” Semi-Structured Data using VARIANT (JSON)  
âœ” Role-Based Access Control (RBAC)  
âœ” Secure View-based Data Masking  
âœ” Apache Spark Batch Processing  
âœ” Structured Streaming Simulation  
âœ” Interactive Streamlit Dashboard  

---

## ğŸ“Š Tech Stack

| Layer           | Technology                         |
|-----------------|------------------------------------|
| ETL             | Python, Pandas, VADER              |
| Big Data        | Apache Spark (PySpark)             |
| Warehouse       | Snowflake                          |
| Analytics       | Advanced SQL                       |
| Optimization    | Clustering, Time Travel            |
| Security        | RBAC + Secure Views                |
| Streaming       | Structured Streaming Simulation    |
| Visualization   | Streamlit, Plotly                  |
| Version Control | Git & GitHub                       |

---

## ğŸ“ Project Structure

```
Social-Media-Sentiment-Analysis-Pipeline/
â”‚
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ logger.py
â”‚   â”œâ”€â”€ extract.py
â”‚   â”œâ”€â”€ transform.py
â”‚   â”œâ”€â”€ load.py
â”‚   â””â”€â”€ main.py
â”‚
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ app.py
â”‚
â”œâ”€â”€ spark_batch.py
â”œâ”€â”€ spark_streaming.py
â”‚
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ 01_schema_setup.sql
â”‚   â”œâ”€â”€ 02_advanced_queries.sql
â”‚   â”œâ”€â”€ 03_optimization.sql
â”‚   â”œâ”€â”€ 04_security.sql
â”‚   â””â”€â”€ 05_semi_structured.sql
â”‚
â”œâ”€â”€ architecture_diagram.png
â”œâ”€â”€ dashboard_screenshot.png
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## âš™ Data Pipeline Flow

### ğŸ”„ Modular ETL

```
Extract â†’ Clean â†’ Transform â†’ Sentiment Scoring â†’ Load
```

- Data extraction from raw Twitter dataset
- Regex-based text cleaning
- VADER sentiment scoring
- Sentiment classification (Positive / Negative / Neutral)
- Date normalization
- Structured logging
- Config-based thresholds

---

### ğŸ—„ Data Warehouse Layer

Star Schema Implementation:

**Fact Table**
- fact_sentiment

**Dimension Tables**
- dim_user
- dim_date
- dim_platform
- dim_location

Designed for efficient OLAP-style analytical querying.

---

## ğŸ“ˆ Analytics Capabilities

Examples of insights generated:

- ğŸ“Š Sentiment distribution by date
- ğŸ“… Rolling average sentiment trend
- ğŸ† Most positive/negative days ranking
- ğŸ“ˆ Trend analysis using window functions
- ğŸ” Sentiment segmentation by platform/location
- âš¡ Hybrid Spark + Snowflake analytics

---

## ğŸ” Security & Governance

Implemented using enterprise design principles:

- Role-Based Access Control (RBAC)
- Secure View-based column masking
- Schema-level privilege management
- Least privilege enforcement model
- Separation of administrative roles

---

## âš¡ Big Data & Streaming

### ğŸš€ Apache Spark Batch Processing

- Sentiment distribution aggregation
- Daily average sentiment calculation
- Distributed computation over large dataset

### ğŸ”„ Structured Streaming (Simulation)

- Micro-batch processing concept
- Continuous aggregation demonstration
- Real-time analytics simulation

---

## ğŸ“Š Interactive Dashboard

Built using Streamlit and Plotly.

Features:

- KPI metrics (Total, Positive, Negative, Neutral)
- Sentiment distribution pie chart
- Daily sentiment trend line chart
- Sentiment score histogram
- Platform-based segmentation
- Interactive filtering (date & sentiment)

![Dashboard Preview](dashboard_screenshot.png)

---

## â–¶ How to Run Locally

### 1ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 2ï¸âƒ£ Run ETL Pipeline

```bash
cd etl
python main.py
```

### 3ï¸âƒ£ Execute Snowflake SQL Scripts

Run scripts inside Snowflake worksheet from `sql/` folder.

### 4ï¸âƒ£ Run Spark Batch Job

```bash
py -3.10 spark_batch.py
```

### 5ï¸âƒ£ Launch Dashboard

```bash
cd dashboard
streamlit run app.py
```

---

## ğŸ“š What This Project Demonstrates

This project showcases:

âœ… End-to-end Data Engineering pipeline  
âœ… Modular ETL architecture  
âœ… Cloud Data Warehouse implementation  
âœ… Big Data processing with Spark  
âœ… Semi-structured data handling  
âœ… Advanced SQL analytics mastery  
âœ… Enterprise security design  
âœ… Performance tuning techniques  
âœ… Production-style project organization  
âœ… Interactive analytical visualization  

---

## ğŸ‘¨â€ğŸ’» Author

**Suman Dandapat**  
Data Engineering & Analytics Enthusiast  

---